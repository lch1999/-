{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "num_classes = 7\n",
    "#img_rows, img_cols = 605, 700\n",
    "img_rows, img_cols = 140, 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load success!\n",
      "(1758, 140, 140, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_image(img_name):\n",
    "    im = Image.open(img_name).convert('RGB')\n",
    "    #im.save(img_name+\".jpg\")\n",
    "    #im = tf.gfile.FastGFile(img_name, 'rb').read()\n",
    "    #img_data = tf.image.decode_jpeg(im)\n",
    "    #img_data = tf.image.convert_image_dtype(img_data, dtype=tf.float32)\n",
    "    #resized = tf.image.resize_images(img_data, [30, 30], method=0)\n",
    "    #print(resized)\n",
    "    #im.show()\n",
    "    data = np.array(im)\n",
    "    return data\n",
    "\n",
    "images = []\n",
    "\n",
    "filename = os.listdir('D://alldata/all_black140gauss1')\n",
    "#print(filename)\n",
    "for fn in filename:\n",
    "    if fn.endswith('.jpg'):\n",
    "        fd = os.path.join('D://alldata/all_black140gauss1',fn)\n",
    "        #print(fd[3])\n",
    "        #data1 = read_image(fd)\n",
    "        #data2 = tf.image.convert_image_dtype(data1, dtype=tf.float32)\n",
    "        #data3 = tf.image.resize_images(data2, [30, 30], method=0) \n",
    "        #images.append(data3)\n",
    "        images.append(read_image(fd))\n",
    "print('load success!')\n",
    "X = np.array(images)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEUTROPHIL\n",
      "['0' '0' '1' ..., '1' '0' '0']\n",
      "['0' '0' '0' '0' '0' '0' '1' '0' '1' '1' '2' '2' '1' '5' '4' '0' '0' '0'\n",
      " '2' '4' '0' '0' '2' '0' '0' '0' '1' '6' '2' '4' '1' '1' '0' '0' '0' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '1' '0' '1' '0' '4' '1' '0'\n",
      " '1' '0' '6' '0' '0' '0' '0' '0' '0' '4' '0' '2' '1' '0' '0' '2' '0' '4'\n",
      " '0' '0' '0' '4' '1' '6' '0' '0' '1' '4' '2' '0' '5' '0' '1' '0' '1' '0'\n",
      " '0' '2' '1' '6' '0' '0' '0' '2' '6' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '2' '0' '1' '0' '0' '0' '4' '0' '1' '0' '5' '0' '1' '1' '3' '0' '0' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '0' '1' '1' '0' '1' '1' '0' '0'\n",
      " '0' '0' '1' '4' '1' '0' '2' '1' '2' '2' '2' '0' '0' '0' '0' '0' '2' '2'\n",
      " '0' '0' '0' '0' '0' '1' '0' '1' '2' '4' '0' '0' '1' '0' '5' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '2' '0' '0' '4' '1' '1' '0' '1' '0' '0' '4' '0' '0'\n",
      " '0' '2' '0' '0' '1' '4' '2' '0' '0' '1' '0' '0' '0' '2' '4' '0' '4' '0'\n",
      " '0' '4' '0' '0' '1' '0' '0' '0' '0' '4' '1' '0' '0' '6' '0' '0' '0' '1'\n",
      " '0' '2' '0' '0' '4' '0' '4' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '2'\n",
      " '2' '0' '1' '1' '0' '0' '0' '0' '4' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '2' '2' '0' '2' '0' '0' '0' '0' '0' '1' '2' '2' '0' '2'\n",
      " '0' '0' '0' '0' '0' '1' '1' '0' '0' '1' '0' '0' '1' '0' '4' '1' '1' '0'\n",
      " '0' '6' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '4'\n",
      " '1' '0' '2' '6' '0' '1' '1' '1' '0' '1' '0' '0' '0' '0' '2' '4' '0' '2'\n",
      " '0' '0' '4' '0' '1' '0' '1' '0' '0' '1']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import keras\n",
    "csv_reader = csv.reader(open(\"D://alldata/labels1.csv\"))\n",
    "for row in csv_reader:\n",
    "    column1 = [row[0]for row in csv_reader]\n",
    "    #print(column1)\n",
    "    \n",
    "\n",
    "Y = np.array(column1)\n",
    "print(Y[4])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 0)\n",
    "\n",
    "\n",
    "img_type = 3\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_type, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_type, img_rows, img_cols)\n",
    "    input_shape = (img_type, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, img_type)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, img_type)\n",
    "    input_shape = (img_rows, img_cols, img_type)\n",
    "    \n",
    "    \n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i] == 'Basal': #Basal cell of prostate epithelium  前列腺上皮基底细胞（1136）\n",
    "        Y_train[i] = 0\n",
    "    elif Y_train[i] == 'CNS': #CNS neuron (sensu Vertebrata) 中枢神经系统神经元（椎骨感觉）（356）\n",
    "        Y_train[i] = 1\n",
    "    elif Y_train[i] == 'NEUTROPHIL': #中性白细胞\n",
    "        Y_train[i] = 2\n",
    "    elif Y_train[i] == 'BASOPHIL': #嗜碱细胞\n",
    "        Y_train[i] = 3\n",
    "    elif Y_train[i] == 'EOSINOPHIL': #嗜酸红细胞\n",
    "        Y_train[i] = 4\n",
    "    elif Y_train[i] == 'MONOCYTE': #单核白血球\n",
    "        Y_train[i] = 5\n",
    "    elif Y_train[i] == 'LYMPHOCYTE': #淋巴细胞\n",
    "        Y_train[i] = 6\n",
    "    else:\n",
    "        print('ERROR')\n",
    "        \n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i] == 'Basal': #Basal cell of prostate epithelium  前列腺上皮基底细胞（1136）\n",
    "        Y_test[i] = 0\n",
    "    elif Y_test[i] == 'CNS': #CNS neuron (sensu Vertebrata) 中枢神经系统神经元（椎骨感觉）（356）\n",
    "        Y_test[i] = 1\n",
    "    elif Y_test[i] == 'NEUTROPHIL': #中性白细胞\n",
    "        Y_test[i] = 2\n",
    "    elif Y_test[i] == 'BASOPHIL': #嗜碱细胞\n",
    "        Y_test[i] = 3\n",
    "    elif Y_test[i] == 'EOSINOPHIL': #嗜酸红细胞\n",
    "        Y_test[i] = 4\n",
    "    elif Y_test[i] == 'MONOCYTE': #单核白血球\n",
    "        Y_test[i] = 5\n",
    "    elif Y_test[i] == 'LYMPHOCYTE': #淋巴细胞\n",
    "        Y_test[i] = 6\n",
    "    else:\n",
    "        print('ERROR')\n",
    "\n",
    "print(Y_train)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1406, 140, 140, 3)\n",
      "(1406,)\n",
      "(352, 140, 140, 3)\n",
      "(352,)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train =  tf.reshape(X_train, [1406, 140*140*3])\n",
    "X_test =  tf.reshape(X_test, [352, 140*140*3])\n",
    "print(Y_train[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train\n",
    "x_test = X_test\n",
    "y_train = Y_train\n",
    "y_test = Y_test\n",
    "print(type(x_train))\n",
    "print(type(x_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x_train=x_train.eval()\n",
    "    print(type(x_train))\n",
    "    x_test=x_test.eval()\n",
    "    print(type(x_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790184921764\n",
      "0.610795454545\n",
      "\n",
      "predict:\n",
      " ['0' '0' '1' ..., '1' '0' '0']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1470ab5465b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#print ('decision_function:\\n', clf.decision_function(x_train))     #每一列的值代表到各类别的距离\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'\\npredict:\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mx1_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 第0列的范围\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mx2_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 第1列的范围\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_min\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx1_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200j\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2_min\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx2_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200j\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 生成网格采样点\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#x, y = np.split(data, (4,), axis = 1)\n",
    "#x = x[:, :2]\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.39)\n",
    " \n",
    "clf = svm.SVC(C = 0.8, kernel = 'rbf', gamma = 20)         #调用svm.svc\n",
    "clf.fit(x_train, y_train.ravel())\n",
    " \n",
    "print (clf.score(x_train, y_train))  # 精度\n",
    "y_hat = clf.predict(x_train)\n",
    "#show_accuracy(y_hat, y_train, '训练集')\n",
    "print (clf.score(x_test, y_test))\n",
    "y_hat = clf.predict(x_test)\n",
    "#show_accuracy(y_hat, y_test, '测试集')\n",
    " \n",
    "#print ('decision_function:\\n', clf.decision_function(x_train))     #每一列的值代表到各类别的距离\n",
    "print ('\\npredict:\\n', clf.predict(x_train))             \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x_train=x_train.eval()\n",
    "    print(type(x_train))\n",
    "    y_train=y_train.eval()\n",
    "    print(type(y_train))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
